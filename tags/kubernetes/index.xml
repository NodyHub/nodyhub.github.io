<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Kubernetes on Nody´s blog</title>
    <link>https://nodyhub.github.io/tags/kubernetes/</link>
    <description>Nody´s blog (Kubernetes)</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sat, 27 Jun 2020 11:39:55 +0200</lastBuildDate>
    
    <atom:link href="https://nodyhub.github.io/tags/kubernetes/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Verify your Kubernetes Cluster Network Policies: From Faith to Proof</title>
      <link>https://nodyhub.github.io/posts/2020-06-kubernetes-network-policy-verification/</link>
      <pubDate>Sat, 27 Jun 2020 11:39:55 +0200</pubDate>
      
      <guid>https://nodyhub.github.io/posts/2020-06-kubernetes-network-policy-verification/</guid>
      <description>&lt;p&gt;Implement a technical check that verifies implemented security measurements. In case of network policy, try to establish a blocked network connection. Keep the checks as simple as possible and propagate the results in existing monitoring solution.&lt;/p&gt;
&lt;h2 id=&#34;intro&#34;&gt;Intro&lt;/h2&gt;
&lt;p&gt;Welcome to my first blog post. I decided to drop my first letters on one of my favoured research topics: &lt;a href=&#34;https://kubernetes.io/&#34;&gt;Kubernetes&lt;/a&gt;. To be more specific, this blog post addresses network policy verification in Kubernetes.&lt;/p&gt;
&lt;p&gt;It is an ongoing discussion as a security consultant to rate if something &amp;ldquo;is secure&amp;rdquo; and to motivate people to trust in the recommended solution that its secure. People always argue and discuss about feelings – something feels not secure // I feel not confi with the solution // are you sure that it is secure // whatever. So, you may now ask yourself how to handle such situations? To be honest, one must find a way to convince people that the introduced approach is &amp;ldquo;secure&amp;rdquo;. As a technician I have trust in my solutions, but how to convince someone who has no trust?&lt;/p&gt;
&lt;p&gt;This blog post addresses continuous verification of introduced security measurements, with &lt;a href=&#34;https://nodyhub.github.io/posts/kubernetes-basics/#network-policies&#34;&gt;Kubernetes Network Policies&lt;/a&gt; as an example.&lt;/p&gt;
&lt;h2 id=&#34;technical-background&#34;&gt;Technical Background&lt;/h2&gt;
&lt;p&gt;For a basic understanding, it would be from relevance to have some knowledge in the following topics:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://nodyhub.github.io/posts/kubernetes-basics/#kubernetes-itself&#34;&gt;Kubernetes Basics&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://nodyhub.github.io/posts/kubernetes-basics/#networking&#34;&gt;Kubernetes Networking&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://nodyhub.github.io/posts/kubernetes-basics/#network-policies&#34;&gt;Kubernetes Network Policies&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;solution&#34;&gt;Solution&lt;/h2&gt;
&lt;p&gt;I am absolutely not a mathematician or old Greek, but &lt;strong&gt;reductio ad absurdum&lt;/strong&gt; describes how we are going to propose an approach to convert my trust into provable trust.&lt;/p&gt;
&lt;h3 id=&#34;general-approach&#34;&gt;General approach&lt;/h3&gt;
&lt;p&gt;The easiest way to summarize the solution is the phrase &lt;strong&gt;PoC||GTFO&lt;/strong&gt;. But, what does this exactly mean?&lt;/p&gt;
&lt;p&gt;Similar to test driven development one can create test cases for infrastructure components that verify that implemented security measurements are sufficient. A lot of people do handle Kubernetes as a magic black box, or at least they speak about it like that. To put light into the dark, a lot of features and functionalities are implemented in basic Unix features – especially in terms of security on container level.&lt;/p&gt;
&lt;p&gt;The major question is now – &lt;strong&gt;How do we verify that implemented features are sufficient? Just test it.&lt;/strong&gt; Since we know that at the end of the day a lot of security measurements in Kubernetes are implemented by the container runtime environment, we can explicit test for them. To verify that a measurement is sufficient, a technical test can be implemented that focus on the feature.&lt;/p&gt;
&lt;p&gt;Before one create a test, it is necessary to &lt;strong&gt;investigate the implemented measurements and figure out how they are realized&lt;/strong&gt;. Based on that knowledge one can &lt;strong&gt;implement a simple check&lt;/strong&gt;. The overall approach is to implement a check &lt;strong&gt;based on the KISS principle&lt;/strong&gt;. Test for container escapes, test for resource exhaustion or test for possible network communication. Multiple tests can be &lt;strong&gt;performed with simple Unix command line tools&lt;/strong&gt; or other quick hacks or code snippets from Stack Overflow ;o). After executing these checks, the program returns with a return code that informs about a success or a failure. Such result can be evaluated, and the status propagated – technically spoke, &lt;strong&gt;check continiously and evaluate the return code&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;The magic question is now, how can we &lt;strong&gt;continuously monitor&lt;/strong&gt; if security measurements stays valid? It’s easy – we use the &lt;strong&gt;same approach as the rest of the cluster workload&lt;/strong&gt; is monitored.&lt;/p&gt;
&lt;p&gt;If a Kubernetes cluster is used to ship an application, somewhere the health state of the Pods is monitored. Normally, there is a dashboard with fancy pie charts and other useful information and typically there is also a place that shows which containers are up and running. If we want to propagate the &lt;strong&gt;failure&lt;/strong&gt; of a &lt;strong&gt;security checks&lt;/strong&gt; into the dashboard the easiest way is to let the container &lt;strong&gt;crash continuously&lt;/strong&gt;. The status of the crashed container is &lt;strong&gt;propagated into&lt;/strong&gt; the normal &lt;strong&gt;container monitoring lifecycle&lt;/strong&gt; and follow-up actions must be performed.&lt;/p&gt;
&lt;h3 id=&#34;technical-implementation&#34;&gt;Technical Implementation&lt;/h3&gt;
&lt;p&gt;As an example how to create a proof of concept for a security measurement I decided to implement a check for &lt;a href=&#34;https://nodyhub.github.io/posts/kubernetes-basics/#network-policies&#34;&gt;Network Policies&lt;/a&gt;. What is the easiest way to check if traffic is filter? Right – try to connect to the target should not be available. In this situation we may also be also interested if certain other hosts are available.&lt;/p&gt;
&lt;p&gt;That sounds like a small project, which can be implemented in a few lines of code. That is perfect to start learning a programming language like Rust, Go or classy C, right? No – absolutely not in our situation. We need a quick implementable check for our measurement. The check should be easy understandable, implementable, reproducible, and so on. It is just a TCP connection – so I decided to use netcat and some bash and that’s it. The check itself fits into one line:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;echo foo | ncat $TARGET $PORT &amp;gt; /dev/null 2&amp;gt;&amp;amp;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;If a connection can be established the command above will be zero. If the command above fails, because a connection cannot be established, the return code is not zero. The evaluation can also be done in one line, as following:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[[&lt;/span&gt; $? !&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;]]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Combining both commands from above with some shell loops and sleep timers in a &lt;a href=&#34;https://github.com/NodyHub/docker-k8s-resources/blob/master/docker-images/test-tcp/test.sh&#34;&gt;shell script&lt;/a&gt; and move the shell script in a &lt;a href=&#34;https://github.com/NodyHub/docker-k8s-resources/blob/master/docker-images/test-tcp/Dockerfile&#34;&gt;Dockerfile&lt;/a&gt;, we are good to go to have our continuous security measurement verification in place. As soon the image is build and pushed to a container registry, it can even be executed in a Kubernetes cluster with a respective &lt;a href=&#34;https://github.com/NodyHub/docker-k8s-resources/blob/master/docker-images/test-tcp/test-tcp.yaml&#34;&gt;deployment&lt;/a&gt;. It is even possible to label the deployment in the same manner like a deployed application. This is an opportunity to cross-check implemented Network Policies. Furthermore, Kubernetes allows to inject configuration into container so that the to-be-checked hosts can be adjusted on the fly.&lt;/p&gt;
&lt;h3 id=&#34;demo&#34;&gt;Demo&lt;/h3&gt;
&lt;p&gt;As demo show I have set up a cluster and my security test should ensure that we have access to the internet on port 80 and the MongoDB from my namespace is not accessible on its default port.&lt;/p&gt;
&lt;p&gt;An excerpt from the deployed &lt;a href=&#34;https://kubernetes.io/docs/concepts/configuration/configmap/&#34;&gt;Configmap&lt;/a&gt; configuration would be following:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;apiVersion&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;v1&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;kind&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;ConfigMap&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;data&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;allow.lst&lt;/span&gt;: |&lt;span style=&#34;color:#e6db74&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    &lt;/span&gt;    &lt;span style=&#34;color:#ae81ff&#34;&gt;1.1.1.1&lt;/span&gt;:&lt;span style=&#34;color:#ae81ff&#34;&gt;80&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;deny.lst&lt;/span&gt;: |&lt;span style=&#34;color:#e6db74&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    &lt;/span&gt;    &lt;span style=&#34;color:#ae81ff&#34;&gt;mongo:27017&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;After deploying the container, we can see in the log output that the checks are successful as desired:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ kubectl logs test-tcp-564f4b9b58-spjmp
&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;25/06/2020 14:52:00 | DEBUG&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; Check hosts from allow.lst to be available
&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;25/06/2020 14:52:00 | INFO&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; 1.1.1.1:80 is accessible
&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;25/06/2020 14:52:00 | DEBUG&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; Check hosts from deny.lst to be not available
&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;25/06/2020 14:52:01 | INFO&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; mongo:27017 not accessible
&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;25/06/2020 14:52:01 | DEBUG&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; wait &lt;span style=&#34;color:#ae81ff&#34;&gt;60&lt;/span&gt; seconds and repeat
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;To verify that our script is sufficient working we can add another host to the &lt;code&gt;deny.lst&lt;/code&gt;, which we know that is accessible, but should not. The configmap can be adjusted during usage in the cluster and the updated value is propagated into the pods:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ kubectl logs test-tcp-564f4b9b58-spjmp
&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;…&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;25/06/2020 14:58:02 | DEBUG&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; Check hosts from allow.lst to be available
&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;25/06/2020 14:58:02 | INFO&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; 1.1.1.1:80 is accessible
&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;25/06/2020 14:58:02 | DEBUG&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; Check hosts from deny.lst to be not available
&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;25/06/2020 14:58:02 | INFO&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; mongo:27017 not accessible
&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;25/06/2020 14:58:02 | ERROR&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; 1.1.1.1:80 is accessible, but should not be !!
$
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;As we can see the pod crashed and the cluster always tries to restart the pod. These crashes are propagated into the in-place container monitoring solution. The support or operations team that monitors the cluster health status can now react and create a ticket or even remediate the issue by performing a role-back of previous enrolled changes. The overall status change would have after remediation an output like the following:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ kubectl get pods -w
NAME                        READY   STATUS             RESTARTS   AGE
test-tcp-564f4b9b58-spjmp   1/1     Running            &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;          5m43s
test-tcp-564f4b9b58-spjmp   0/1     Error              &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;          6m9s
test-tcp-564f4b9b58-spjmp   0/1     Error              &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;          6m11s
test-tcp-564f4b9b58-spjmp   0/1     CrashLoopBackOff   &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;          6m26s
test-tcp-564f4b9b58-spjmp   0/1     Error              &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;          6m27s
test-tcp-564f4b9b58-spjmp   0/1     CrashLoopBackOff   &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;          6m43s
test-tcp-564f4b9b58-spjmp   0/1     Error              &lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;          6m56s
test-tcp-564f4b9b58-spjmp   0/1     CrashLoopBackOff   &lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;          7m7s
test-tcp-564f4b9b58-spjmp   0/1     Error              &lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;          7m52s
test-tcp-564f4b9b58-spjmp   0/1     CrashLoopBackOff   &lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;          8m6s
test-tcp-564f4b9b58-spjmp   0/1     Error              &lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;          9m23s
test-tcp-564f4b9b58-spjmp   0/1     CrashLoopBackOff   &lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;          9m36s
test-tcp-564f4b9b58-spjmp   1/1     Running            &lt;span style=&#34;color:#ae81ff&#34;&gt;6&lt;/span&gt;          12m
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;In my case I performed a role-back of the configuration and the pod could restart and go back into the continuous while loop and stays in the running status.&lt;/p&gt;
&lt;h2 id=&#34;summary&#34;&gt;Summary&lt;/h2&gt;
&lt;p&gt;The general solution to generate trust for an implemented security measurement is by &lt;strong&gt;implementing a check&lt;/strong&gt; that verifies the assumptions. To make use of the implemented check, it must also &lt;strong&gt;easily integratable into existing life cycle&lt;/strong&gt;, e.g., continuous monitoring.&lt;/p&gt;
&lt;p&gt;We have seen an approach how to &lt;strong&gt;use basic Unix command line tools&lt;/strong&gt; to verify the validity of an implemented security measurement. The implementation of a technical PoC is kept as simple as possible to reduce bugs in the test itself.&lt;/p&gt;
&lt;p&gt;The overall intention is to &lt;strong&gt;reduce the amount of time that is spend during endless meetings that discuss if a measurement is sufficient or not&lt;/strong&gt;. Using the same time to &lt;strong&gt;implement a PoC&lt;/strong&gt; will reveal in a provable statement, which can be rechecked every now and then.&lt;/p&gt;
&lt;h2 id=&#34;remarks&#34;&gt;Remarks&lt;/h2&gt;
&lt;p&gt;I remembered during writing of this blogpost that the topic is highly related to the BlackHat London 2019 talk &lt;a href=&#34;https://www.blackhat.com/eu-19/briefings/schedule/#reverse-engineering-and-exploiting-builds-in-the-cloud-17287&#34;&gt;Reverse Engineering and Exploiting Builds in the Cloud&lt;/a&gt;. The researchers state in their session how security checks can be continuously performed during the build process for the build pipeline. &lt;a href=&#34;https://twitter.com/brompwnie&#34;&gt;@brompwnie&lt;/a&gt; developed for security checks the tool &lt;a href=&#34;https://github.com/brompwnie/botb&#34;&gt;Break out the Box (BOtB)&lt;/a&gt;, which can perform various security checks continuously.&lt;/p&gt;
&lt;p&gt;As a little disclaimer, the implemented bash script is a quick and dirty hack, which should show that not always an over-engineered solution is necessary to perform simple tasks ;o)&lt;/p&gt;
&lt;h2 id=&#34;links&#34;&gt;Links&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/NodyHub/docker-k8s-resources/blob/master/docker-images/test-tcp/test.sh&#34;&gt;Shell script&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/NodyHub/docker-k8s-resources/blob/master/docker-images/test-tcp/Dockerfile&#34;&gt;Dockerfile&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://hub.docker.com/r/nodyd/test-tcp&#34;&gt;Docker Hub Image&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/NodyHub/docker-k8s-resources/blob/master/docker-images/test-tcp/test-tcp.yaml&#34;&gt;Kubernetes Resources&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>Training: Docker, Kubernetes &amp; Security in Enterprise Environments</title>
      <link>https://nodyhub.github.io/publication/2020-troopers/</link>
      <pubDate>Fri, 20 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>https://nodyhub.github.io/publication/2020-troopers/</guid>
      <description>&lt;p&gt;Kevin Kelpen &amp;amp; Jan Harrie, TROOPERS20, Heidelberg, Germany&lt;/p&gt;
&lt;h2 id=&#34;abstract&#34;&gt;Abstract&lt;/h2&gt;
&lt;p&gt;Container, Microservices, Kubernetes - all of those terms heavily dominate modern application development teams and processes. This training will explain the key technologies behind those terms and focus on the following main questions:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;How strong and reliable are the isolation capabilities of Docker/Linux/OS containers?&lt;/li&gt;
&lt;li&gt;How do containers affect typical application and network architectures?&lt;/li&gt;
&lt;li&gt;How does Kubernetes affect application deployments and workflows?&lt;/li&gt;
&lt;li&gt;How is “security” integrated into those paradigms?&lt;/li&gt;
&lt;li&gt;What additional attack surface and security challenges are introduced by the changed development landscape and additional tools?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;All agenda topics will be supported by practical exercises and/or demos. At the end of the training, each attendee will have knowledge about the described buzzwords and tools and understand how they impact application architectures, development, and security posture. Additionally, a fully functional Kubernetes cluster is built, as well as relevant security measures implemented and discussed.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Who should attend this training and why?&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;IT Security Professionals who want to:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;understand the technology behind the recent and common buzzwords listed above,&lt;/li&gt;
&lt;li&gt;be able to evaluate the isolation capabilities of container solutions,&lt;/li&gt;
&lt;li&gt;get ideas on how to integrate security into typical DevOps environments and continuous workflows.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Software Architects and Developers who want to:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;learn about potential security vulnerabilities in common practices and tools,&lt;/li&gt;
&lt;li&gt;understand the concerns of the security people,&lt;/li&gt;
&lt;li&gt;improve their development chain by adding automated security checks.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Due to the large amount of tools and technologies, this training will not be able to cover security aspects of every single technology in detail. However, we are happy to receive specific questions before the training to potentially prepare additional material and you will get an overview how to approach unknown/new technologies from a security perspective.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Requirements&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;The attendees should have:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;intermediate knowledge of the Linux bash and a command line-based text editor (e.g. nano or vim)&lt;/li&gt;
&lt;li&gt;a system with WLAN and an SSH client (i.e. PuTTY) which is able to connect via SSH to systems in the Internet.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For the exercises, we provide the needed infrastructure in a cloud environment which the attendees can connect to via SSH.&lt;/p&gt;
&lt;h2 id=&#34;media&#34;&gt;Media&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://insinuator.net/2019/12/troopers20-training-teaser-swim-with-the-whales-docker-devops-security-in-enterprise-environments/&#34;&gt;Blogpost&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>How to Secure OpenShift Environments and What Happens If You Don´t</title>
      <link>https://nodyhub.github.io/publication/2019-devseccon/</link>
      <pubDate>Wed, 20 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://nodyhub.github.io/publication/2019-devseccon/</guid>
      <description>&lt;p&gt;Jan Harrie, DevSecCon, London, United Kingdom&lt;/p&gt;
&lt;h2 id=&#34;abstract&#34;&gt;Abstract&lt;/h2&gt;
&lt;p&gt;OpenShift by Red Hat is one of the major Platform as a Service (PaaS) solutions on the market. It is used to automatically deploy Kubernetes clusters and provides useful extensions for cluster management mixed with some magic under the hood.
Instantiating a Kubernetes cluster is often a crucial step in setting up a modern application stack. But be aware – a lot of configuration parameters are awaiting you. And here several misconfigurations may occur that can lead up to a compromise of the cluster. Privileged containers, tainting of masters and executing workloads on them, missing role-based access controls, and misconfigured Service Accounts are part of the problem.
In this talk, I will explain which configuration parameters of an OpenShift environment are critical to ensure the overall security of the deployed Kubernetes clusters. Implications of misconfigurations will be demonstrated during live demos. Finally, recommendations for a secure configuration are provided.&lt;/p&gt;
&lt;h2 id=&#34;media&#34;&gt;Media&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;../201911_DSC_OpenShift_v1.0_export.pdf&#34;&gt;Slides&lt;/a&gt; or &lt;a href=&#34;https://cutt.ly/HeNpUtD&#34;&gt;Google Slides&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=pa4uZICJRRA&#34;&gt;Recording&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://insinuator.net/2019/11/dsc19-openshift/&#34;&gt;Blogpost&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>TROOPERS19</title>
      <link>https://nodyhub.github.io/publication/2019-troopers/</link>
      <pubDate>Wed, 20 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://nodyhub.github.io/publication/2019-troopers/</guid>
      <description>&lt;p&gt;Heidelberg, Germany&lt;/p&gt;
&lt;h2 id=&#34;threat-modelling-and-beyond-for-cisco-aci&#34;&gt;Threat Modelling and Beyond for Cisco ACI&lt;/h2&gt;
&lt;p&gt;Frank Block &amp;amp; Jan Harrie&lt;/p&gt;
&lt;h3 id=&#34;abstract&#34;&gt;Abstract&lt;/h3&gt;
&lt;p&gt;Cisco Application Centric Infrastructure (ACI) is one of the major solutions in the era of software-defined networking (SDN). Overall, it consists of a) leaf &amp;amp; spine switches (running NX-OS) to connect different endpoints and enforce filtering rules and b) a cluster of Application Policy Infrastructure Controllers to manage the SDN. Such a modern networking approach comes, of course, with its own threats and risks.&lt;/p&gt;
&lt;p&gt;To better understand the threat landscape in the case of the Cisco ACI solution, we performed a first deeper analysis of the system. In this lightning talk we will present the current research results on a theoretical and technical level, existing challenges, and a forecast of the next steps.&lt;/p&gt;
&lt;h3 id=&#34;media&#34;&gt;Media&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;../TROOPERS19_DM_Threat_Modelling_Cisco_ACI.pdf&#34;&gt;Slides&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=2KX3CNDz9PE&#34;&gt;Recording&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;docker-kubernetes--security-in-enterprise-environments&#34;&gt;Docker, Kubernetes &amp;amp; Security in Enterprise Environments&lt;/h2&gt;
&lt;p&gt;Simon Janz &amp;amp; Jan Harrie&lt;/p&gt;
&lt;h3 id=&#34;abstract-1&#34;&gt;Abstract&lt;/h3&gt;
&lt;p&gt;Container, Microservices, Kubernetes - all of those terms heavily dominate modern application development teams and processes. This training will explain the key technologies behind those terms and focus on the following main questions:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;How strong and reliable are the isolation capabilities of Docker/Linux/OS containers?&lt;/li&gt;
&lt;li&gt;How do containers affect typical application and network architectures?&lt;/li&gt;
&lt;li&gt;How does Kubernetes affect application deployments and workflows?&lt;/li&gt;
&lt;li&gt;How is “security” integrated into those paradigms?&lt;/li&gt;
&lt;li&gt;What additional attack surface and security challenges are introduced by the changed development landscape and additional tools?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;All agenda topics will be supported by practical exercises and/or demos. At the end of the training, each attendee will have knowledge about the described buzzwords and tools and understand how they impact application architectures, development, and security posture. Additionally, a fully functional Kubernetes cluster is built, as well as relevant security measures implemented and discussed.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Who should attend this training and why?&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;IT Security Professionals who want to:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;understand the technology behind the recent and common buzzwords listed above,&lt;/li&gt;
&lt;li&gt;be able to evaluate the isolation capabilities of container solutions,&lt;/li&gt;
&lt;li&gt;get ideas on how to integrate security into typical DevOps environments and continuous workflows.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Software Architects and Developers who want to:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;learn about potential security vulnerabilities in common practices and tools,&lt;/li&gt;
&lt;li&gt;understand the concerns of the security people,&lt;/li&gt;
&lt;li&gt;improve their development chain by adding automated security checks.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Due to the large amount of tools and technologies, this training will not be able to cover security aspects of every single technology in detail. However, we are happy to receive specific questions before the training to potentially prepare additional material and you will get an overview how to approach unknown/new technologies from a security perspective.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Requirements&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;The attendees should have:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;intermediate knowledge of the Linux bash and a command line-based text editor (e.g. nano or vim)&lt;/li&gt;
&lt;li&gt;a system with WLAN and an SSH client (i.e. PuTTY) which is able to connect via SSH to systems in the Internet.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For the exercises, we provide the needed infrastructure in a cloud environment which the attendees can connect to via SSH.&lt;/p&gt;
&lt;h3 id=&#34;media-1&#34;&gt;Media&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://insinuator.net/2019/01/tr19-training-k8/&#34;&gt;Blogpost&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>Kubernetes Basics and Principles</title>
      <link>https://nodyhub.github.io/posts/kubernetes-basics/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://nodyhub.github.io/posts/kubernetes-basics/</guid>
      <description>&lt;p&gt;This blogpost is intended to be a background knowledge section for further posts. The content is all around Kubernetes basic principles and reflects more a dictionary then a legitim blog post. The section itself may not explain every nuance of the topic – only as much as necessary as needed in other posts.&lt;/p&gt;
&lt;p&gt;The list of topics and explanations may be updated over the time.&lt;/p&gt;
&lt;h2 id=&#34;kubernetes-itself&#34;&gt;Kubernetes itself&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://kubernetes.io/&#34;&gt;Kubernetes&lt;/a&gt; is a production-grade container orchestration solution that is available on all modern cloud provider for executing and orchestrating containerized applications. The applications are distributed over multiple nodes, which execute the application containers. The container itself are executed by the installed container runtime interface, while the management of the containers is handled by Kubernetes.&lt;/p&gt;
&lt;p&gt;Kubernetes offers fine-grained permission management capabilities that can be set for user and groups – implemented by &lt;a href=&#34;https://kubernetes.io/docs/reference/access-authn-authz/rbac/&#34;&gt;Role Based Access Control (RBAC)&lt;/a&gt;. The scope can be set to the overall cluster or only to a &lt;a href=&#34;https://kubernetes.io/docs/concepts/overview/working-with-objects/namespaces/&#34;&gt;Namespace&lt;/a&gt;. A best-practice to develop a cluster application is to assign projects to its own or multiple Namespaces and hand over the project team administrative access in the development environment. The administrator can manage service accounts, roles, storage, services, pods and further namespace scoped resources. More details about Kubernetes can be read in the article &lt;a href=&#34;https://kubernetes.io/docs/concepts/overview/what-is-kubernetes/&#34;&gt;What is Kubernetes?&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The most interesting part is that an administrator can install and configure the cluster and slice it into pieces, which can be managed within these pieces independent.&lt;/p&gt;
&lt;h2 id=&#34;networking&#34;&gt;Networking&lt;/h2&gt;
&lt;p&gt;One of the Kubernetes advantages (maybe also disadvantages) is that it is built like a big and flexible framework. Besides different storage classes and different authentication provider, the implementation of the &lt;a href=&#34;https://kubernetes.io/docs/concepts/cluster-administration/networking/&#34;&gt;Cluster Networking&lt;/a&gt; can be exchanged. Kubernetes offers the flexibility to set for the overall cluster one network plugin. These network plugins are created and maintained independent of the Kubernetes project, like &lt;a href=&#34;https://www.projectcalico.org/&#34;&gt;Calico&lt;/a&gt; or &lt;a href=&#34;https://cilium.io&#34;&gt;Cilium&lt;/a&gt;. Even the cloud provider like AWS implement their own plugins for an optimal integration into the cloud environment. The decision which network plugin depends on the requirements. Requirements can be reliability, encryption, speed, or Network Policies. Only one network plugin can be configured for a cluster.&lt;/p&gt;
&lt;h2 id=&#34;network-policies&#34;&gt;Network Policies&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://kubernetes.io/docs/concepts/services-networking/network-policies/&#34;&gt;Network Policies&lt;/a&gt; are the kind of resources in Kubernetes that can be used to define stateless firewall rules for managed cluster workload. The policies are applied on Pod’s, namespaces or a combination of namespaces and pods.&lt;/p&gt;
&lt;p&gt;Network Policies are defined on an allow-listing approach and deployed in a namespace. The policy starts with a pod selection – based on the label – on which pod’s it should be applied. Hence, the same labels can be set to different pods, a group selection is also possible. If the Network Policy should be valid for every resource, a wild-card selector (&lt;code&gt;{}&lt;/code&gt;) can even be used. This selection defines on which resource the rule should be applied. The next part is if it is an ingress or an egress rule and which ports (&lt;a href=&#34;https://en.wikipedia.org/wiki/OSI_model#Layer_4:_Transport_Layer&#34;&gt;OSI layer 4&lt;/a&gt;) are allowed – the port is optional. Finally, the rule defines the network communication opposite. The opposite is a pod, a namespace, a combination of pod and namespace or IP block in CIDR notation. Pod and namespace are selected based on the labels, which must have been set previously. If no Network Policy is configured for a pod, the pod can communicate over the network without any restriction.&lt;/p&gt;
&lt;p&gt;A best practice approach is to deploy a deny all network policy and configure in an explicit allow-listing approach intended communication paths.
But, be aware, this may escalate quickly 😉&lt;/p&gt;
&lt;h2 id=&#34;label-and-selectors&#34;&gt;Label and Selectors&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/&#34;&gt;Label and Selectors&lt;/a&gt; is the concept in Kubernetes, which is used to perform group operations on similar resources&lt;/p&gt;
&lt;p&gt;Before a resource can be selected, these resources must be labelled. Kubernetes offers the feature to label each resource with key value pairs. These key value pairs can be selected freely, e.g., &lt;code&gt;foo: bar&lt;/code&gt;, &lt;code&gt;stage: dev&lt;/code&gt; or &lt;code&gt;app: frontend&lt;/code&gt;. Labels can be set to almost every object (not sure if it is possible to label all resources). The semantic of these labels is only in the interpretation of the people that set these labels. Okay, nowadays there might be technical resources that depend on such labels to make decisions. Objects from one type can be selected by selectors. These selectors are analogous to the labels and must match labels that have been previous set, e.g., &lt;code&gt;foo: bar&lt;/code&gt;, &lt;code&gt;stage: dev&lt;/code&gt; or &lt;code&gt;app: frontend&lt;/code&gt;.&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>